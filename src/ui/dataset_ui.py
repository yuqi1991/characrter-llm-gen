import gradio as gr
import pandas as pd
import json
from src.services import character_service, scenario_service, dataset_service


def create_dataset_ui():
    """Creates the UI for dataset management."""

    selected_dataset_id_state = gr.State(None)

    def load_all_dropdowns():
        datasets = dataset_service.get_all_datasets_for_display()
        dataset_names = [d["name"] for d in datasets]
        characters = character_service.get_all_characters()
        character_names = [c["name"] for c in characters]
        # åˆå§‹æ—¶åœºæ™¯é€‰æ‹©æ¡†ä¸ºç©ºï¼Œéœ€è¦å…ˆé€‰æ‹©è§’è‰²
        return (
            gr.update(choices=dataset_names),
            gr.update(choices=character_names),
            gr.update(choices=[], value=[]),  # ç©ºçš„åœºæ™¯é€‰æ‹©æ¡†
        )

    def format_dialogue(dialogue):
        if isinstance(dialogue, str):
            try:
                dialogue = json.loads(dialogue)
            except json.JSONDecodeError:
                return dialogue
        return json.dumps(dialogue, ensure_ascii=False, indent=2)

    def update_corpus_view(dataset_id, scenario_filters):
        if not dataset_id:
            empty_df = pd.DataFrame(columns=["dialogue", "scenarios"])
            return empty_df, "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ•°æ®é›†ã€‚", gr.update(choices=[], value=[])

        corpus_data = dataset_service.get_corpus_by_dataset(
            dataset_id, scenario_filters
        )
        if corpus_data:
            for item in corpus_data:
                item["dialogue"] = format_dialogue(item.get("dialogue", "{}"))
        corpus_df = (
            pd.DataFrame(corpus_data)
            if corpus_data
            else pd.DataFrame(columns=["dialogue", "scenarios"])
        )

        stats = dataset_service.get_dataset_stats(dataset_id)
        stats_md = f"**æ€»è¯­æ–™æ•°**: {stats['total_corpus_count']}\n\n**å„åœºæ™¯è¯­æ–™æ•°**:\n"
        if stats["scenario_counts"]:
            stats_md += "\n".join(
                f"- {name}: {count}" for name, count in stats["scenario_counts"].items()
            )
        else:
            stats_md += "- æš‚æ— åœºæ™¯ç»Ÿè®¡"

        dataset_details = dataset_service.get_dataset_details_by_id(dataset_id)
        scenario_choices = (
            dataset_details.get("scenario_names", []) if dataset_details else []
        )
        return corpus_df, stats_md, gr.update(choices=scenario_choices)

    def on_select_dataset(dataset_name):
        if not dataset_name:
            return None, "", "", None, [], *update_corpus_view(None, [])

        details = dataset_service.get_dataset_details(dataset_name)
        if details:
            corpus_df, stats_md, scenario_filter_update = update_corpus_view(
                details["id"], []
            )
            return (
                details["id"],
                details["name"],
                details["description"],
                details["character_name"],
                details["scenario_names"],
                corpus_df,
                stats_md,
                scenario_filter_update,
            )
        return None, "", "", None, [], *update_corpus_view(None, [])

    def on_save_dataset(dataset_id, name, description, character, scenarios):
        if not name or not character:
            gr.Warning("æ•°æ®é›†åç§°å’Œç»‘å®šè§’è‰²ä¸èƒ½ä¸ºç©ºï¼")
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
            )

        try:
            new_id = dataset_service.create_or_update_dataset(
                dataset_id, name, description, character, scenarios
            )
            gr.Info(f"æ•°æ®é›† '{name}' å·²æˆåŠŸä¿å­˜ï¼")
            datasets_dd, _, _ = load_all_dropdowns()
            corpus_df, stats_md, scenario_filter_update = update_corpus_view(new_id, [])
            return (
                datasets_dd,
                new_id,
                name,
                description,
                character,
                scenarios,
                corpus_df,
                stats_md,
                scenario_filter_update,
            )
        except ValueError as e:
            gr.Warning(str(e))
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
            )

    def on_delete_dataset(dataset_id):
        if not dataset_id:
            gr.Warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè¦åˆ é™¤çš„æ•°æ®é›†ï¼")
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
            )

        success = dataset_service.delete_dataset(dataset_id)
        if success:
            gr.Info("æ•°æ®é›†å·²æˆåŠŸåˆ é™¤ã€‚")
            new_datasets, _, _ = load_all_dropdowns()
            empty_form = (None, "", "", None, [])
            empty_corpus_view = update_corpus_view(None, [])
            return new_datasets, *empty_form, *empty_corpus_view
        else:
            gr.Warning("åˆ é™¤æ•°æ®é›†å¤±è´¥ï¼")
            return (
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
                gr.update(),
            )

    def on_export_corpus(dataset_id, export_format):
        """å¯¼å‡ºè¯­æ–™åº“æ•°æ®"""
        if not dataset_id:
            gr.Warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ•°æ®é›†ï¼")
            return None

        try:
            if export_format == "å®Œæ•´æ ¼å¼ (JSONL)":
                filename = dataset_service.export_dataset_corpus_to_jsonl(dataset_id)
            elif export_format == "è®­ç»ƒæ ¼å¼ (JSONL)":
                filename = dataset_service.export_dataset_corpus_to_standard_format(
                    dataset_id
                )
            else:
                gr.Warning("è¯·é€‰æ‹©å¯¼å‡ºæ ¼å¼ï¼")
                return None

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os

            if os.path.exists(filename):
                gr.Info(
                    "è¯­æ–™åº“å·²æˆåŠŸå¯¼å‡ºï¼æ–‡ä»¶å·²å‡†å¤‡å¥½ä¸‹è½½ã€‚",
                )
                return gr.update(value=filename, visible=True)
            else:
                gr.Warning("æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
                return gr.update(visible=False)
        except Exception as e:
            gr.Warning(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            return gr.update(visible=False)

    def on_add_new_dataset():
        return None, "", "", None, []

    def on_character_change_in_dataset(character_name):
        """å½“è§’è‰²ä¸‹æ‹‰èœå•å˜åŒ–æ—¶ï¼Œæ›´æ–°åœºæ™¯å¤šé€‰æ¡†çš„é€‰é¡¹"""
        if not character_name:
            return gr.update(choices=[], value=[])

        # NOTE: è¿™è€¦åˆäº†ä¸¤ä¸ªæœåŠ¡ï¼Œä½†ä¸ºäº†UIçš„å“åº”æ€§æ˜¯å€¼å¾—çš„
        character = character_service.get_character_by_name(character_name)
        if character:
            scenarios = scenario_service.get_scenarios_by_character(character["id"])
            scenario_names = [s["name"] for s in scenarios]
            return gr.update(choices=scenario_names, value=[])
        return gr.update(choices=[], value=[])

    def on_delete_corpus_by_scenario(dataset_id, scenarios_to_delete):
        """å¤„ç†æŒ‰åœºæ™¯åˆ é™¤è¯­æ–™çš„æŒ‰é’®ç‚¹å‡»äº‹ä»¶"""
        if not dataset_id:
            gr.Warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ•°æ®é›†ï¼")
            return gr.update(), gr.update(), gr.update()
        if not scenarios_to_delete:
            gr.Warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¦åˆ é™¤è¯­æ–™çš„åœºæ™¯ï¼")
            return gr.update(), gr.update(), gr.update()

        try:
            deleted_count = dataset_service.delete_corpus_by_scenarios(
                dataset_id, scenarios_to_delete
            )
            gr.Info(f"æˆåŠŸåˆ é™¤äº† {deleted_count} æ¡è¯­æ–™ã€‚")
            # Refresh corpus view and stats
            return update_corpus_view(dataset_id, [])
        except Exception as e:
            gr.Warning(f"åˆ é™¤è¯­æ–™å¤±è´¥: {e}")
            return gr.update(), gr.update(), gr.update()

    def on_detect_invalid_data(dataset_id):
        """æ£€æµ‹ä¸åˆè§„èŒƒçš„æ•°æ®"""
        if not dataset_id:
            # æ£€æµ‹æ‰€æœ‰æ•°æ®é›†
            try:
                result = dataset_service.detect_invalid_corpus_data()
                total_checked = result["total_checked"]
                invalid_count = len(result["invalid_entries"])

                if invalid_count == 0:
                    detection_info = f"âœ… æ£€æµ‹å®Œæˆï¼šæ€»å…±æ£€æŸ¥äº† {total_checked} æ¡è¯­æ–™ï¼Œ**æœªå‘ç°**ä¸åˆè§„èŒƒæ•°æ®"
                    detection_details = "æ‰€æœ‰æ•°æ®æ ¼å¼æ­£ç¡®ï¼"
                    return detection_info, detection_details, gr.update(visible=False)
                else:
                    detection_info = f"âš ï¸ æ£€æµ‹å®Œæˆï¼šæ€»å…±æ£€æŸ¥äº† {total_checked} æ¡è¯­æ–™ï¼Œå‘ç° **{invalid_count}** æ¡ä¸åˆè§„èŒƒæ•°æ®"

                    # æ„å»ºè¯¦ç»†ä¿¡æ¯
                    details_lines = ["### ä¸åˆè§„èŒƒæ•°æ®è¯¦æƒ…ï¼š\n"]
                    for i, entry in enumerate(
                        result["invalid_entries"][:10]
                    ):  # åªæ˜¾ç¤ºå‰10æ¡
                        details_lines.append(f"**{i+1}. è¯­æ–™ID: {entry['corpus_id']}**")
                        details_lines.append(f"- æ•°æ®é›†: {entry['dataset_name']}")
                        details_lines.append(f"- é—®é¢˜: {', '.join(entry['issues'])}")
                        details_lines.append(
                            f"- æ•°æ®æ ·æœ¬: `{entry['dialogue_sample'][:100]}...`"
                        )
                        details_lines.append("")

                    if len(result["invalid_entries"]) > 10:
                        details_lines.append(
                            f"*...è¿˜æœ‰ {len(result['invalid_entries']) - 10} æ¡æ•°æ®æœªæ˜¾ç¤º*"
                        )

                    detection_details = "\n".join(details_lines)
                    return detection_info, detection_details, gr.update(visible=True)

            except Exception as e:
                error_msg = f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}"
                return error_msg, "", gr.update(visible=False)
        else:
            # æ£€æµ‹ç‰¹å®šæ•°æ®é›†
            try:
                result = dataset_service.detect_invalid_corpus_data(dataset_id)
                total_checked = result["total_checked"]
                invalid_count = len(result["invalid_entries"])

                dataset_details = dataset_service.get_dataset_details_by_id(dataset_id)
                dataset_name = (
                    dataset_details["name"] if dataset_details else f"ID {dataset_id}"
                )

                if invalid_count == 0:
                    detection_info = (
                        f"âœ… æ•°æ®é›† '{dataset_name}' æ£€æµ‹å®Œæˆï¼šæ£€æŸ¥äº† {total_checked} æ¡è¯­æ–™ï¼Œ"
                        f"**æœªå‘ç°**ä¸åˆè§„èŒƒæ•°æ®"
                    )
                    detection_details = "è¯¥æ•°æ®é›†æ‰€æœ‰æ•°æ®æ ¼å¼æ­£ç¡®ï¼"
                    return detection_info, detection_details, gr.update(visible=False)
                else:
                    detection_info = (
                        f"âš ï¸ æ•°æ®é›† '{dataset_name}' æ£€æµ‹å®Œæˆï¼šæ£€æŸ¥äº† {total_checked} æ¡è¯­æ–™ï¼Œ"
                        f"å‘ç° **{invalid_count}** æ¡ä¸åˆè§„èŒƒæ•°æ®"
                    )

                    # æ„å»ºè¯¦ç»†ä¿¡æ¯
                    details_lines = ["### ä¸åˆè§„èŒƒæ•°æ®è¯¦æƒ…ï¼š\n"]
                    for i, entry in enumerate(
                        result["invalid_entries"][:10]
                    ):  # åªæ˜¾ç¤ºå‰10æ¡
                        details_lines.append(f"**{i+1}. è¯­æ–™ID: {entry['corpus_id']}**")
                        details_lines.append(f"- é—®é¢˜: {', '.join(entry['issues'])}")
                        details_lines.append(
                            f"- æ•°æ®æ ·æœ¬: `{entry['dialogue_sample'][:100]}...`"
                        )
                        details_lines.append("")

                    if len(result["invalid_entries"]) > 10:
                        details_lines.append(
                            f"*...è¿˜æœ‰ {len(result['invalid_entries']) - 10} æ¡æ•°æ®æœªæ˜¾ç¤º*"
                        )

                    detection_details = "\n".join(details_lines)
                    return detection_info, detection_details, gr.update(visible=True)

            except Exception as e:
                error_msg = f"âŒ æ£€æµ‹å¤±è´¥: {str(e)}"
                return error_msg, "", gr.update(visible=False)

    def on_clean_invalid_data(dataset_id, dry_run):
        """æ¸…ç†ä¸åˆè§„èŒƒçš„æ•°æ®"""
        try:
            result = dataset_service.clean_invalid_corpus_data(dataset_id, dry_run)
            detected_count = result["detected_count"]
            deleted_count = result["deleted_count"]

            if detected_count == 0:
                gr.Info("æœªå‘ç°éœ€è¦æ¸…ç†çš„ä¸åˆè§„èŒƒæ•°æ®")
                return "æœªå‘ç°éœ€è¦æ¸…ç†çš„æ•°æ®", gr.update(), gr.update(), gr.update()

            if dry_run:
                cleanup_info = f"ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šå‘ç° {detected_count} æ¡ä¸åˆè§„èŒƒæ•°æ®ï¼Œå¦‚éœ€åˆ é™¤è¯·ç‚¹å‡»'ç¡®è®¤æ¸…ç†'"
                gr.Info(f"è¯•è¿è¡Œå®Œæˆï¼šå‘ç° {detected_count} æ¡ä¸åˆè§„èŒƒæ•°æ®")
                return cleanup_info, gr.update(), gr.update(), gr.update()
            else:
                cleanup_info = f"âœ… æ¸…ç†å®Œæˆï¼šæˆåŠŸåˆ é™¤ {deleted_count}/{detected_count} æ¡ä¸åˆè§„èŒƒæ•°æ®"
                gr.Info(f"æ¸…ç†å®Œæˆï¼šæˆåŠŸåˆ é™¤ {deleted_count} æ¡æ•°æ®")

                # åˆ·æ–°è¯­æ–™é¢„è§ˆå’Œç»Ÿè®¡
                if dataset_id:
                    corpus_df, stats_md, scenario_filter_update = update_corpus_view(
                        dataset_id, []
                    )
                    return cleanup_info, corpus_df, stats_md, scenario_filter_update
                else:
                    return cleanup_info, gr.update(), gr.update(), gr.update()

        except Exception as e:
            error_msg = f"âŒ æ¸…ç†å¤±è´¥: {str(e)}"
            gr.Warning(f"æ¸…ç†å¤±è´¥: {str(e)}")
            return error_msg, gr.update(), gr.update(), gr.update()

    with gr.Blocks(analytics_enabled=False) as dataset_ui:
        gr.Markdown("## ğŸ“š è¯­æ–™æ•°æ®é›†ç®¡ç†\nç®¡ç†å’Œé…ç½®ç”¨äºç”Ÿæˆä»»åŠ¡çš„æ•°æ®é›†ã€‚")
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### æ•°æ®é›†é…ç½®")
                dataset_dropdown = gr.Dropdown(label="é€‰æ‹©æ•°æ®é›†")
                with gr.Group():
                    dataset_name = gr.Textbox(label="æ•°æ®é›†åç§°")
                    dataset_description = gr.Textbox(label="æ•°æ®é›†æè¿°", lines=3)
                    character_dropdown = gr.Dropdown(label="ç»‘å®šè§’è‰²")
                    scenario_multiselect = gr.Dropdown(
                        label="ç»‘å®šåœºæ™¯æ ‡ç­¾ (å¯å¤šé€‰)",
                        multiselect=True,
                        interactive=True,
                    )
                with gr.Row():
                    add_btn = gr.Button("âœ¨ æ·»åŠ æ–°æ•°æ®é›†")
                    delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤æ•°æ®é›†", variant="stop")
                save_btn = gr.Button("ğŸ’¾ ä¿å­˜æ•°æ®é›†é…ç½®", variant="primary")

                # æ·»åŠ å¯¼å‡ºåŠŸèƒ½åŒºåŸŸ
                gr.Markdown("### è¯­æ–™åº“å¯¼å‡º")
                with gr.Group():
                    export_format = gr.Dropdown(
                        label="å¯¼å‡ºæ ¼å¼",
                        choices=["å®Œæ•´æ ¼å¼ (JSONL)", "è®­ç»ƒæ ¼å¼ (JSONL)"],
                        value="å®Œæ•´æ ¼å¼ (JSONL)",
                        info="å®Œæ•´æ ¼å¼åŒ…å«æ‰€æœ‰å…ƒæ•°æ®ï¼Œè®­ç»ƒæ ¼å¼é€‚ç”¨äºæ¨¡å‹å¾®è°ƒ",
                    )
                    export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºè¯­æ–™åº“", variant="secondary")
                    export_file = gr.File(label="ä¸‹è½½æ–‡ä»¶", visible=False)

                # æ·»åŠ æ•°æ®æ¸…ç†åŠŸèƒ½åŒºåŸŸ
                gr.Markdown("### æ•°æ®è´¨é‡ç®¡ç†")
                with gr.Group():
                    gr.Markdown("**æ£€æµ‹å’Œæ¸…ç†ä¸åˆè§„èŒƒçš„è¯­æ–™æ•°æ®**")
                    with gr.Row():
                        detect_btn = gr.Button("ğŸ” æ£€æµ‹é—®é¢˜æ•°æ®", variant="secondary")
                        clean_dry_run_btn = gr.Button(
                            "ğŸ§ª è¯•è¿è¡Œæ¸…ç†", variant="secondary"
                        )
                        clean_confirm_btn = gr.Button("ğŸ—‘ï¸ ç¡®è®¤æ¸…ç†", variant="stop")

                        # æ£€æµ‹ç»“æœæ˜¾ç¤º
                    detection_result = gr.Markdown(visible=True)
                    detection_details = gr.Markdown(visible=True)

                    # æ¸…ç†ç»“æœæ˜¾ç¤º
                    cleanup_result = gr.Markdown(visible=True)

            with gr.Column(scale=2):
                gr.Markdown("### æ•°æ®é›†é¢„è§ˆä¸ç»Ÿè®¡")
                with gr.Row():
                    filter_by_scenario_dropdown = gr.Dropdown(
                        label="æŒ‰åœºæ™¯ç­›é€‰é¢„è§ˆ", multiselect=True, scale=4
                    )
                    delete_corpus_by_scenario_btn = gr.Button(
                        "ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­åœºæ™¯çš„è¯­æ–™", variant="stop", scale=1
                    )
                corpus_preview_df = gr.Dataframe(
                    headers=["dialogue", "scenarios"],
                    label="è¯­æ–™é¢„è§ˆ",
                    row_count=(10, "dynamic"),
                    wrap=True,
                )
                stats_display = gr.Markdown(label="æ•°æ®é›†ç»Ÿè®¡")

        outputs_left_panel = [
            selected_dataset_id_state,
            dataset_name,
            dataset_description,
            character_dropdown,
            scenario_multiselect,
        ]
        outputs_right_panel = [
            corpus_preview_df,
            stats_display,
            filter_by_scenario_dropdown,
        ]

        dataset_ui.load(
            fn=load_all_dropdowns,
            outputs=[dataset_dropdown, character_dropdown, scenario_multiselect],
        )
        dataset_dropdown.change(
            fn=on_select_dataset,
            inputs=[dataset_dropdown],
            outputs=[*outputs_left_panel, *outputs_right_panel],
        )

        character_dropdown.change(
            fn=on_character_change_in_dataset,
            inputs=[character_dropdown],
            outputs=[scenario_multiselect],
        )

        add_btn.click(fn=on_add_new_dataset, outputs=outputs_left_panel)
        save_btn.click(
            fn=on_save_dataset,
            inputs=[
                selected_dataset_id_state,
                dataset_name,
                dataset_description,
                character_dropdown,
                scenario_multiselect,
            ],
            outputs=[dataset_dropdown, *outputs_left_panel, *outputs_right_panel],
        )
        delete_btn.click(
            fn=on_delete_dataset,
            inputs=[selected_dataset_id_state],
            outputs=[dataset_dropdown, *outputs_left_panel, *outputs_right_panel],
        )

        # æ·»åŠ å¯¼å‡ºäº‹ä»¶å¤„ç†
        export_btn.click(
            fn=on_export_corpus,
            inputs=[selected_dataset_id_state, export_format],
            outputs=[export_file],
        )

        filter_by_scenario_dropdown.change(
            fn=update_corpus_view,
            inputs=[selected_dataset_id_state, filter_by_scenario_dropdown],
            outputs=outputs_right_panel,
        )

        delete_corpus_by_scenario_btn.click(
            fn=on_delete_corpus_by_scenario,
            inputs=[selected_dataset_id_state, filter_by_scenario_dropdown],
            outputs=[
                corpus_preview_df,
                stats_display,
                filter_by_scenario_dropdown,
            ],
        )

        # æ·»åŠ æ•°æ®æ¸…ç†äº‹ä»¶å¤„ç†
        detect_btn.click(
            fn=on_detect_invalid_data,
            inputs=[selected_dataset_id_state],
            outputs=[detection_result, detection_details, cleanup_result],
        )

        clean_dry_run_btn.click(
            fn=lambda dataset_id: on_clean_invalid_data(dataset_id, dry_run=True),
            inputs=[selected_dataset_id_state],
            outputs=[
                cleanup_result,
                corpus_preview_df,
                stats_display,
                filter_by_scenario_dropdown,
            ],
        )

        clean_confirm_btn.click(
            fn=lambda dataset_id: on_clean_invalid_data(dataset_id, dry_run=False),
            inputs=[selected_dataset_id_state],
            outputs=[
                cleanup_result,
                corpus_preview_df,
                stats_display,
                filter_by_scenario_dropdown,
            ],
        )

    return dataset_ui
